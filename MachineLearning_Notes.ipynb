{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Practicing the Art of Building a very Basic Machine Learning Model in Python - my first ever!"
      ]
    },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41f5ff9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 100.00%\n",
      "Actual outcomes: [1 0]\n",
      "Predicted outcomes: [1 0]\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Import necessary libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Step 2: Create some sample data (hours studied vs. pass/fail)\n",
    "hours_studied = np.array([2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "pass_fail = np.array([0, 0, 0, 0, 1, 1, 1, 1, 1])  # 0 indicates fail, 1 indicates pass\n",
    "\n",
    "# Step 3: Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(hours_studied.reshape(-1, 1), pass_fail, test_size=0.2, random_state=42)\n",
    "\n",
    "## hours_studied.reshape(-1, 1): This reshapes the array to a format suitable for our machine learning model. Think of it as organizing the ingredients in a way the recipe (model) prefers.\n",
    "## pass_fail: These are the labels indicating whether a student passed or failed.\n",
    "## test_size=0.2: It means 20% of the data will be set aside for testing, while 80% will be used for training.\n",
    "## random_state=42: This ensures that every time you run the code, the data splitting remains consistent. It's like using the same cookbook edition for a particular recipe.\n",
    "\n",
    "# Step 4: Create a Logistic Regression model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Step 5: Train the model on the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Step 6: Make predictions on the test data\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "## ^Uses the reserved ingredients in the test set (X_test) to see how well the Model performs. \n",
    "\n",
    "# Step 7: Evaluate the model's accuracy\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "\n",
    "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Step 8: Display the results\n",
    "print(\"Actual outcomes:\", y_test)\n",
    "print(\"Predicted outcomes:\", predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b857997",
   "metadata": {},
   "source": [
    "# Simple Learning & Predicting Using Machine-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c7f7f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alijazibrizvi/anaconda3/lib/python3.11/site-packages/sklearn/base.py:464: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['HipHop', 'Dance'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier # package = \"sklearn\" (A package that comes with scikitlearn library), module = \"tree\", class = \"DecisionTreeClassifier\"\n",
    "\n",
    "df = pd.read_csv(r\"/Users/alijazibrizvi/Downloads/music.csv\") # Gender of \"0\": Female; Gender of \"1\": Male\n",
    "df\n",
    "\n",
    "# Goal: to Predict Preference of Genre of a person based on Age & Gender\n",
    "\n",
    "### Steps:\n",
    "\n",
    "# 1) Split this Dataset into Two: One with the \"Age\" & \"Gender\" columns, the Other with the \"Genre\" column\n",
    "##^ Whenever we Train a Model, we give it 2 Datasets: an \"Input\" set (in this case, the \"Age\" & \"Gender\" columns) and an \"Output\" (contains the predictions - in this case, the \"Genre\" column) set\n",
    "###^ Once the Model is Trained, we give it a New Input set(s) to Predict from\n",
    "###^ For example, after the initial training, give the Model an Input set of [21, 1] to Predict Favorite Genre of (Combination of \"Age\" & \"Gender\" not in Original Dataset but which the Model will Predict based on its earlier Training)\n",
    "\n",
    "# Let's Split the Dataset\n",
    "X = df.drop(columns = [\"genre\"]) # Removing the \"Genre\" column to Create the \"Input\" set\n",
    "y = df[\"genre\"] # Showing Only the \"Genre\" column to define it as the \"Output\" set\n",
    "\n",
    "model = DecisionTreeClassifier() # Creating a New Instance of the \"DecisionTreeClassifier\" Class\n",
    "\n",
    "## We Have the Model^. Now, we Need to Train it to Learn Patterns in the Data\n",
    "model.fit(X, y) # Training the Model: This is How it will Learn the Patterns in the Data - model.fit(*input set*, *output set*)\n",
    "predictions = model.predict([ [21, 1], [22, 0] ]) # Predict Favorite Genre for Each of the Two Input sets: a 21-year-old Male (\"[21, 1]\") and a 22-year-old Female (\"[22, 0]\")\n",
    "predictions # There ya go! \"HipHop\" & \"Dance\" are the Respective (and quite Accurate, from the Data) Predictions!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd77999",
   "metadata": {},
   "source": [
    "# Measuring the Accuracy of a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "544b39de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To Measure the Accuracy of your Model, you must Split your Dataset into Two: One for Training & the Other for Testing\n",
    "\n",
    "# The More Complex the Problem is, the More Data we Need to Train the Model for Accuracy\n",
    "\n",
    "## Generally: Allocate 70-80% of your Data for Training & the Remaining 20-30% for Testing\n",
    "###^ Usually, the Higher the Test Size, the Lower your Model's Accuracy will be\n",
    "###^ The Higher the Quantity and Cleanliness of Data we Give to the Model for Training, the Higher the Model's Accuracy should be\n",
    "###^ Thus, it is Very Important to Clean our Data before Training & Testing our Model\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X = df.drop(columns = [\"genre\"])\n",
    "y = df[\"genre\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size =0.20) # We are Allocating 20% (test_size = 0.2) of our Data for Testing\n",
    "##^ This Function Returns a Tuple; so, we will Unpack it into Four Variables (\"X_train, X_test, ...\")\n",
    "###^ The first 2 variables (\"X_train\", \"X_test\") are the Input Sets for Training & Testing\n",
    "###^ The last 2 variables (\"y_train\", \"y_test\") are the Output Sets for Training & Testing\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train, y_train) # Here, Pass only the Training Dataset\n",
    "predictions = model.predict(X_test) # Pass the Dataset (\"Input set\") that contains Input Values for Testing\n",
    "\n",
    "# Calculating Accuracy of Model by Comparing the result of \"predictions\" to Actual Values of the Output Set for Testing (\"y_test\")\n",
    "                             \n",
    "score = accuracy_score(y_test, predictions) # The \"score\" will be Between 0 and 1\n",
    "score # e.g., \"1.0\" = 100% Accurate!\n",
    "## ^i.e., If you ask it to predict what Genre a 21-year-old Male [21, 1] would like, based on the Model's training, it will predict the Correct Genre 100% of the Time\n",
    "\n",
    "# By the way, Each Time you Run this^ Accuracy Predictor, it might result in a Different Accuracy Value since the Dataset-Splitting Function Randomly Picks Data for Training & Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46d0d50",
   "metadata": {},
   "source": [
    "# Same ML Model^ but with the Addition of Updating the Model with New Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8f3166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from IPython.display import display, clear_output\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Create initial data\n",
    "\n",
    "hours_studied = np.array([2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "pass_fail = np.array([0, 0, 0, 0, 1, 1, 1, 1, 1])\n",
    "\n",
    "# Create and train the initial model\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(hours_studied.reshape(-1, 1), pass_fail)\n",
    "\n",
    "# Function to update and visualize predictions\n",
    "\n",
    "def update_model_and_predict(new_data):\n",
    "    # Update the model with new data\n",
    "    model.fit(new_data[:, 0].reshape(-1, 1), new_data[:, 1])\n",
    "    \n",
    "    # Make predictions on the updated model\n",
    "    predictions = model.predict(hours_studied.reshape(-1, 1))\n",
    "    \n",
    "    # Visualize predictions\n",
    "    clear_output(wait=True)\n",
    "    display(predictions)\n",
    "    time.sleep(2)  # Simulating real-time updates\n",
    "\n",
    "# Simulate live data updates\n",
    "new_data1 = np.array([[11, 1], [12, 1]])\n",
    "update_model_and_predict(new_data1)\n",
    "\n",
    "new_data2 = np.array([[3, 0], [4, 0]])\n",
    "update_model_and_predict(new_data2)\n",
    "\n",
    "## This example defines a function update_model_and_predict that takes in new data, updates the model, and visualizes the predictions. \n",
    "## The clear_output and time.sleep functions simulate the idea of real-time updates in a Jupyter Notebook environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a950451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Changing \"Categorical\" (Written in Letters) Data into Numeric Data for Regression Models, etc.\n",
    "\n",
    "## Encoding Categorical data\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "labelencoder = LabelEncoder()\n",
    "X[:, 3] = labelencoder.fit_transform(X[:, 3]) # \"X[:, 3]\" Look for all rows (\":,\") in the X dataset but Edit only the 3rd (\"... 3]\") row\n",
    "# Then, we set it equal to a Transformation (\"labelencoder.fit_transform\") for the same 3rd row (\"[:, 3]\"), Meaning that - for example - instead of a 'New York' it will have a 1 or 2 or 3, etc.\n",
    "\n",
    "\n",
    "onehotencoder = OneHotEncoder(categorical_features = [3])\n",
    "X = onehotencoder.fit_transform(X).toarray() # This Final Transformation preps our Data so that it is Completely Set as a Row of Numbers Only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c47f80",
   "metadata": {},
   "source": [
    "## Ways of Connecting to Data Source AND/OR Continuously Updating Data:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6893617b",
   "metadata": {},
   "source": [
    "### Connecting to a Data Source:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f1531b",
   "metadata": {},
   "source": [
    "#### Databases (e.g., SQLite, mySQL, PostgreSQL):\n",
    "Use a database connector like sqlite3, mysql-connector, or psycopg2 for respective databases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55045c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "# Connect to SQLite database\n",
    "conn = sqlite3.connect('your_database.db')\n",
    "\n",
    "# Use pandas to read data from a SQL query\n",
    "data = pd.read_sql_query('SELECT * FROM your_table', conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71df1e7a",
   "metadata": {},
   "source": [
    "#### APIs:\n",
    "Use the requests library to fetch data from APIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c67b4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# Make a GET request to an API endpoint\n",
    "response = requests.get('https://api.example.com/data')\n",
    "\n",
    "# Parse JSON response\n",
    "data = response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f35bfe",
   "metadata": {},
   "source": [
    "### Continuously Updating Data:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834d96cd",
   "metadata": {},
   "source": [
    "### Periodic Fetching:\n",
    "Schedule periodic fetches using a library like schedule to update your data at specified intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8183f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import schedule\n",
    "import time\n",
    "\n",
    "def update_data():\n",
    "    # Your data update logic here\n",
    "\n",
    "# Schedule updates every hour\n",
    "schedule.every().hour.do(update_data)\n",
    "\n",
    "while True:\n",
    "    schedule.run_pending()\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9764e005",
   "metadata": {},
   "source": [
    "### Streaming Data:\n",
    "For streaming data, consider using libraries like pandas or websocket-client for WebSocket-based updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1899f6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import websocket\n",
    "\n",
    "def on_message(ws, message):\n",
    "    # Your data processing logic for each streaming message\n",
    "    update_data(message)\n",
    "\n",
    "# Connect to a WebSocket for streaming updates\n",
    "ws = websocket.WebSocketApp('wss://stream.example.com', on_message=on_message)\n",
    "ws.run_forever()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
